## 4.4. Sonstige Anforderungen
Aus der KIV und bereits vorhandenen Gesetzen ergeben sich neben den zuvor beschriebenen Anforderungen Verpflichtungen, welche für den Einsatz und Betrieb von KI-Systemen relevant sind, unabhängig von der jeweiligen Risikokartierung Unternehmen müssen sicherstellen, dass KI-Systeme frei von manipulativen Techniken sind, um die Autonomie, Entscheidungsfindungen und die freie Auswahl von Personen nicht zu beeinträchtigen (Art. 5 Abs. 1 lit. a KIV). Zudem müssen Unternehmen sichere und konforme Produkte auf den Markt bringen, um Sicherheitsrisiken und nachteilige Auswirkungen auf die Gesundheit bei der Verwendung von Produkten zu vermeiden (EG 47 KIV). Wesentlicher Grundgedanke aus der KIV ist, dass Unternehmen sicherstellen, dass KI-Systeme das menschliche Verhalten nicht nachteilig beeinflussen können, um negative Entscheidungen für die physische und psychische Gesundheit sowie die finanziellen Interessen zu verhindern (EG 29 KIV). Insbesondere ist zu unterlassen, dass KI-Systeme für die Risikobewertung und Preisbildung von Kranken- und Lebensversicherungen eingesetzt werden (EG 58 KIV). Zu vermeiden sind erhebliche Auswirkungen auf die Existenzgrundlage, schwerwiegende Konsequenzen für das Leben und die Gesundheit sowie finanzielle Ausgrenzung und Diskriminierung von Personen (EG 47 KIV).
Sofern personenbezogene Daten (Art. 4 Nr. 1 DSGVO) verarbeitet werden, sind zusätzlich datenschutzrechtliche Grundsätze (Art. 5 DSGVO), wie Transparenzvorgaben (Art. 5 Nr. 1 DSGVO i.V.m. Art. 12 ff. DSGVO), in Ergänzung der Anforderungen KI-Systeme transparent und nachvollziehbar mit verständlichen und überprüfbaren Entscheidungsgrundlagen zu gestalten (EG 27 KIV; EG 71 KIV, Anhang IV Nr. 4 KIV), sowie besondere Pflichten zur Erstellung von Dokumentationen (Art. 30 DSGVO) und Risikobewertungen als Datenschutz-Folgenabschätzungen (Art. 35 DSGVO) zu erstellen. Die KIV sieht hierzu besondere Mitwirkungspflichten für Anbieter von Hochrisiko-KI-Systemen vor (Art. 13 KIV; Frank & Heine, 2023). Vollständig automatisierte Entscheidungsfindungen (Art. 22 DSGVO i.V.m. Art. 6 DSGVO und Art. 9 DSGVO) sind vorbehaltlich begrenzter Aufnahmen untersagt, vergleichbar zu den Anforderungen einer menschlichen Aufsichtspflicht zur Überwachung von Hochrisiko-KI-Systemen. Das bedeutet im Resultat, dass Unternehmen die Entscheidungen von KI-Systemen über Bedingungen des Arbeitsverhältnisses, die Beförderung und Beendigung von Arbeitsverhältnissen, für die Zuweisung von Arbeitsaufgaben auf der Grundlage von individuellem Verhalten, persönlichen Eigenschaften oder Merkmalen sowie für die Überwachung oder Bewertung von Beschäftigten aufgrund von Arbeitnehmerrechten verhindern müssen (Frank & Heine, 2023).
Die KIV sieht als technische und organisatorische Maßnahmen vor, dass natürliche Personen mit entsprechender Kompetenz Aufsicht über die KI-Systeme führen (Art. 26 Abs. 2 KIV). Zudem sind für diese Risikokartierung Konformitätserklärungen (Art. 16 lit. g KIV i.V.m. Art. 47 KIV), CE-Kennzeichen (Art. 16 lit. h KIV i.V.m. Anforderungen aus Art. 48 KIV), Registrierungspflichten (Art. 16 lit. i KIV i.V.m. Art. 49 KIV) und Barrierefreiheitsanforderungen zu beachten (Art. 16 lit. l KIV).
Von Interesse sind technische Anforderungen, wie die Verpflichtung für Unternehmen, KI-Anwendungen mit einer intuitiven und leicht verständlichen Benutzeroberfläche bereitzustellen, um die Bedürfnisse der EU-Bürger effizient zu erfüllen.